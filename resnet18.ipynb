{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e546179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_places365(train = True):\n",
    "    if train:\n",
    "        imgs_path = \"/datasets-2/places365/places365_standard/train/\"\n",
    "    else:\n",
    "        imgs_path = \"/datasets-2/places365/places365_standard/val/\"\n",
    "    \n",
    "    file_list = glob.glob(imgs_path + \"*\")\n",
    "    lst = []\n",
    "    class_names = set()\n",
    "    \n",
    "    for class_path in file_list:\n",
    "        class_name = class_path.split(\"/\")[-1]\n",
    "        class_names.add(class_name)\n",
    "        for img_path in glob.glob(class_path + \"/*.jpg\"):\n",
    "            lst.append([img_path, class_name])\n",
    "    return lst, sorted(class_names)\n",
    "\n",
    "def getitem(d, class_map):\n",
    "    # Get image\n",
    "    img = cv2.imread(d[0])\n",
    "    img_tensor = torch.from_numpy(img).float()\n",
    "    img_tensor = img_tensor.permute(2, 0, 1)\n",
    "    \n",
    "    # Get class_id (0-364)\n",
    "    class_name = d[1]\n",
    "    class_id = class_map[class_name]\n",
    "    class_id = torch.tensor([class_id]).item()\n",
    "    \n",
    "    return img_tensor, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42765b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model setup\n"
     ]
    }
   ],
   "source": [
    "from utils.vgg16 import VGG\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = VGG('VGG16', num_classes = 365)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "print(\"Model setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45e8eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, class_names = get_places365(train = True)\n",
    "test_data, _ = get_places365(train = False)\n",
    "class_names = sorted(class_names)\n",
    "class_map = {c:i for i, c in zip(range(len(class_names)), class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9cc0e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airfield',\n",
       " 'airplane_cabin',\n",
       " 'airport_terminal',\n",
       " 'alcove',\n",
       " 'alley',\n",
       " 'amphitheater',\n",
       " 'amusement_arcade',\n",
       " 'amusement_park',\n",
       " 'apartment_building-outdoor',\n",
       " 'aquarium',\n",
       " 'aqueduct',\n",
       " 'arcade',\n",
       " 'arch',\n",
       " 'archaelogical_excavation',\n",
       " 'archive',\n",
       " 'arena-hockey',\n",
       " 'arena-performance',\n",
       " 'arena-rodeo',\n",
       " 'army_base',\n",
       " 'art_gallery',\n",
       " 'art_school',\n",
       " 'art_studio',\n",
       " 'artists_loft',\n",
       " 'assembly_line',\n",
       " 'athletic_field-outdoor',\n",
       " 'atrium-public',\n",
       " 'attic',\n",
       " 'auditorium',\n",
       " 'auto_factory',\n",
       " 'auto_showroom',\n",
       " 'badlands',\n",
       " 'bakery-shop',\n",
       " 'balcony-exterior',\n",
       " 'balcony-interior',\n",
       " 'ball_pit',\n",
       " 'ballroom',\n",
       " 'bamboo_forest',\n",
       " 'bank_vault',\n",
       " 'banquet_hall',\n",
       " 'bar',\n",
       " 'barn',\n",
       " 'barndoor',\n",
       " 'baseball_field',\n",
       " 'basement',\n",
       " 'basketball_court-indoor',\n",
       " 'bathroom',\n",
       " 'bazaar-indoor',\n",
       " 'bazaar-outdoor',\n",
       " 'beach',\n",
       " 'beach_house',\n",
       " 'beauty_salon',\n",
       " 'bedchamber',\n",
       " 'bedroom',\n",
       " 'beer_garden',\n",
       " 'beer_hall',\n",
       " 'berth',\n",
       " 'biology_laboratory',\n",
       " 'boardwalk',\n",
       " 'boat_deck',\n",
       " 'boathouse',\n",
       " 'bookstore',\n",
       " 'booth-indoor',\n",
       " 'botanical_garden',\n",
       " 'bow_window-indoor',\n",
       " 'bowling_alley',\n",
       " 'boxing_ring',\n",
       " 'bridge',\n",
       " 'building_facade',\n",
       " 'bullring',\n",
       " 'burial_chamber',\n",
       " 'bus_interior',\n",
       " 'bus_station-indoor',\n",
       " 'butchers_shop',\n",
       " 'butte',\n",
       " 'cabin-outdoor',\n",
       " 'cafeteria',\n",
       " 'campsite',\n",
       " 'campus',\n",
       " 'canal-natural',\n",
       " 'canal-urban',\n",
       " 'candy_store',\n",
       " 'canyon',\n",
       " 'car_interior',\n",
       " 'carrousel',\n",
       " 'castle',\n",
       " 'catacomb',\n",
       " 'cemetery',\n",
       " 'chalet',\n",
       " 'chemistry_lab',\n",
       " 'childs_room',\n",
       " 'church-indoor',\n",
       " 'church-outdoor',\n",
       " 'classroom',\n",
       " 'clean_room',\n",
       " 'cliff',\n",
       " 'closet',\n",
       " 'clothing_store',\n",
       " 'coast',\n",
       " 'cockpit',\n",
       " 'coffee_shop',\n",
       " 'computer_room',\n",
       " 'conference_center',\n",
       " 'conference_room',\n",
       " 'construction_site',\n",
       " 'corn_field',\n",
       " 'corral',\n",
       " 'corridor',\n",
       " 'cottage',\n",
       " 'courthouse',\n",
       " 'courtyard',\n",
       " 'creek',\n",
       " 'crevasse',\n",
       " 'crosswalk',\n",
       " 'dam',\n",
       " 'delicatessen',\n",
       " 'department_store',\n",
       " 'desert-sand',\n",
       " 'desert-vegetation',\n",
       " 'desert_road',\n",
       " 'diner-outdoor',\n",
       " 'dining_hall',\n",
       " 'dining_room',\n",
       " 'discotheque',\n",
       " 'doorway-outdoor',\n",
       " 'dorm_room',\n",
       " 'downtown',\n",
       " 'dressing_room',\n",
       " 'driveway',\n",
       " 'drugstore',\n",
       " 'elevator-door',\n",
       " 'elevator_lobby',\n",
       " 'elevator_shaft',\n",
       " 'embassy',\n",
       " 'engine_room',\n",
       " 'entrance_hall',\n",
       " 'escalator-indoor',\n",
       " 'excavation',\n",
       " 'fabric_store',\n",
       " 'farm',\n",
       " 'fastfood_restaurant',\n",
       " 'field-cultivated',\n",
       " 'field-wild',\n",
       " 'field_road',\n",
       " 'fire_escape',\n",
       " 'fire_station',\n",
       " 'fishpond',\n",
       " 'flea_market-indoor',\n",
       " 'florist_shop-indoor',\n",
       " 'food_court',\n",
       " 'football_field',\n",
       " 'forest-broadleaf',\n",
       " 'forest_path',\n",
       " 'forest_road',\n",
       " 'formal_garden',\n",
       " 'fountain',\n",
       " 'galley',\n",
       " 'garage-indoor',\n",
       " 'garage-outdoor',\n",
       " 'gas_station',\n",
       " 'gazebo-exterior',\n",
       " 'general_store-indoor',\n",
       " 'general_store-outdoor',\n",
       " 'gift_shop',\n",
       " 'glacier',\n",
       " 'golf_course',\n",
       " 'greenhouse-indoor',\n",
       " 'greenhouse-outdoor',\n",
       " 'grotto',\n",
       " 'gymnasium-indoor',\n",
       " 'hangar-indoor',\n",
       " 'hangar-outdoor',\n",
       " 'harbor',\n",
       " 'hardware_store',\n",
       " 'hayfield',\n",
       " 'heliport',\n",
       " 'highway',\n",
       " 'home_office',\n",
       " 'home_theater',\n",
       " 'hospital',\n",
       " 'hospital_room',\n",
       " 'hot_spring',\n",
       " 'hotel-outdoor',\n",
       " 'hotel_room',\n",
       " 'house',\n",
       " 'hunting_lodge-outdoor',\n",
       " 'ice_cream_parlor',\n",
       " 'ice_floe',\n",
       " 'ice_shelf',\n",
       " 'ice_skating_rink-indoor',\n",
       " 'ice_skating_rink-outdoor',\n",
       " 'iceberg',\n",
       " 'igloo',\n",
       " 'industrial_area',\n",
       " 'inn-outdoor',\n",
       " 'islet',\n",
       " 'jacuzzi-indoor',\n",
       " 'jail_cell',\n",
       " 'japanese_garden',\n",
       " 'jewelry_shop',\n",
       " 'junkyard',\n",
       " 'kasbah',\n",
       " 'kennel-outdoor',\n",
       " 'kindergarden_classroom',\n",
       " 'kitchen',\n",
       " 'lagoon',\n",
       " 'lake-natural',\n",
       " 'landfill',\n",
       " 'landing_deck',\n",
       " 'laundromat',\n",
       " 'lawn',\n",
       " 'lecture_room',\n",
       " 'legislative_chamber',\n",
       " 'library-indoor',\n",
       " 'library-outdoor',\n",
       " 'lighthouse',\n",
       " 'living_room',\n",
       " 'loading_dock',\n",
       " 'lobby',\n",
       " 'lock_chamber',\n",
       " 'locker_room',\n",
       " 'mansion',\n",
       " 'manufactured_home',\n",
       " 'market-indoor',\n",
       " 'market-outdoor',\n",
       " 'marsh',\n",
       " 'martial_arts_gym',\n",
       " 'mausoleum',\n",
       " 'medina',\n",
       " 'mezzanine',\n",
       " 'moat-water',\n",
       " 'mosque-outdoor',\n",
       " 'motel',\n",
       " 'mountain',\n",
       " 'mountain_path',\n",
       " 'mountain_snowy',\n",
       " 'movie_theater-indoor',\n",
       " 'museum-indoor',\n",
       " 'museum-outdoor',\n",
       " 'music_studio',\n",
       " 'natural_history_museum',\n",
       " 'nursery',\n",
       " 'nursing_home',\n",
       " 'oast_house',\n",
       " 'ocean',\n",
       " 'office',\n",
       " 'office_building',\n",
       " 'office_cubicles',\n",
       " 'oilrig',\n",
       " 'operating_room',\n",
       " 'orchard',\n",
       " 'orchestra_pit',\n",
       " 'pagoda',\n",
       " 'palace',\n",
       " 'pantry',\n",
       " 'park',\n",
       " 'parking_garage-indoor',\n",
       " 'parking_garage-outdoor',\n",
       " 'parking_lot',\n",
       " 'pasture',\n",
       " 'patio',\n",
       " 'pavilion',\n",
       " 'pet_shop',\n",
       " 'pharmacy',\n",
       " 'phone_booth',\n",
       " 'physics_laboratory',\n",
       " 'picnic_area',\n",
       " 'pier',\n",
       " 'pizzeria',\n",
       " 'playground',\n",
       " 'playroom',\n",
       " 'plaza',\n",
       " 'pond',\n",
       " 'porch',\n",
       " 'promenade',\n",
       " 'pub-indoor',\n",
       " 'racecourse',\n",
       " 'raceway',\n",
       " 'raft',\n",
       " 'railroad_track',\n",
       " 'rainforest',\n",
       " 'reception',\n",
       " 'recreation_room',\n",
       " 'repair_shop',\n",
       " 'residential_neighborhood',\n",
       " 'restaurant',\n",
       " 'restaurant_kitchen',\n",
       " 'restaurant_patio',\n",
       " 'rice_paddy',\n",
       " 'river',\n",
       " 'rock_arch',\n",
       " 'roof_garden',\n",
       " 'rope_bridge',\n",
       " 'ruin',\n",
       " 'runway',\n",
       " 'sandbox',\n",
       " 'sauna',\n",
       " 'schoolhouse',\n",
       " 'science_museum',\n",
       " 'server_room',\n",
       " 'shed',\n",
       " 'shoe_shop',\n",
       " 'shopfront',\n",
       " 'shopping_mall-indoor',\n",
       " 'shower',\n",
       " 'ski_resort',\n",
       " 'ski_slope',\n",
       " 'sky',\n",
       " 'skyscraper',\n",
       " 'slum',\n",
       " 'snowfield',\n",
       " 'soccer_field',\n",
       " 'stable',\n",
       " 'stadium-baseball',\n",
       " 'stadium-football',\n",
       " 'stadium-soccer',\n",
       " 'stage-indoor',\n",
       " 'stage-outdoor',\n",
       " 'staircase',\n",
       " 'storage_room',\n",
       " 'street',\n",
       " 'subway_station-platform',\n",
       " 'supermarket',\n",
       " 'sushi_bar',\n",
       " 'swamp',\n",
       " 'swimming_hole',\n",
       " 'swimming_pool-indoor',\n",
       " 'swimming_pool-outdoor',\n",
       " 'synagogue-outdoor',\n",
       " 'television_room',\n",
       " 'television_studio',\n",
       " 'temple-asia',\n",
       " 'throne_room',\n",
       " 'ticket_booth',\n",
       " 'topiary_garden',\n",
       " 'tower',\n",
       " 'toyshop',\n",
       " 'train_interior',\n",
       " 'train_station-platform',\n",
       " 'tree_farm',\n",
       " 'tree_house',\n",
       " 'trench',\n",
       " 'tundra',\n",
       " 'underwater-ocean_deep',\n",
       " 'utility_room',\n",
       " 'valley',\n",
       " 'vegetable_garden',\n",
       " 'veterinarians_office',\n",
       " 'viaduct',\n",
       " 'village',\n",
       " 'vineyard',\n",
       " 'volcano',\n",
       " 'volleyball_court-outdoor',\n",
       " 'waiting_room',\n",
       " 'water_park',\n",
       " 'water_tower',\n",
       " 'waterfall',\n",
       " 'watering_hole',\n",
       " 'wave',\n",
       " 'wet_bar',\n",
       " 'wheat_field',\n",
       " 'wind_farm',\n",
       " 'windmill',\n",
       " 'yard',\n",
       " 'youth_hostel',\n",
       " 'zen_garden']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cf2f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def loader(data, indices, i, batch_size, class_map):\n",
    "    n = len(data)\n",
    "    return DataLoader([getitem(data[indices[idx]], class_map) for idx in range(i, min(n, i+batch_size))], batch_size = 128)\n",
    "\n",
    "def train(model, train_data, optimizer, criterion, device, class_map):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    batch_size = 128\n",
    "    n = len(train_data)\n",
    "    indices = np.random.permutation(n)\n",
    "    \n",
    "    for i in tqdm(range(0, n, batch_size), total = n//batch_size, position = 0):\n",
    "        trainloader = loader(train_data, indices, i, batch_size, class_map)\n",
    "        for data in trainloader:\n",
    "            counter += 1\n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass.\n",
    "            outputs = model(image)\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_running_loss += loss.item()\n",
    "            # Calculate the accuracy.\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            train_running_correct += (preds == labels).sum().item()\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            # Update the weights.\n",
    "            optimizer.step()\n",
    "\n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc =  (train_running_correct / n)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, val_data, criterion, device, class_map):\n",
    "    model.eval()\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    batch_size = 128\n",
    "    n = len(val_data)\n",
    "    indices = range(n)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, n, batch_size), total = n//batch_size, position = 0):\n",
    "            validloader = loader(val_data, indices, i, batch_size, class_map)\n",
    "            for data in validloader:\n",
    "                counter += 1\n",
    "                image, labels = data\n",
    "                image = image.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # Forward pass.\n",
    "                outputs = model(image)\n",
    "                # Calculate the loss.\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_running_loss += loss.item()\n",
    "                # Calculate the accuracy.\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                valid_running_correct += (preds == labels).sum().item()\n",
    "        \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = (valid_running_correct / n)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb035401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 147/380 [03:39<05:48,  1.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5468/3158640275.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     train_accs.append(train_acc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mval_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5468/1935021734.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_data, criterion, device, class_map)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mvalidloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5468/1935021734.py\u001b[0m in \u001b[0;36mloader\u001b[0;34m(data, indices, i, batch_size, class_map)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5468/1935021734.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5468/1763683073.py\u001b[0m in \u001b[0;36mgetitem\u001b[0;34m(d, class_map)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Get image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for _ in range(epochs):\n",
    "    print(f\"Epoch {_}\")\n",
    "#     train_loss, train_acc = train(model, train_data, optimizer, criterion, device, class_map)\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accs.append(train_acc)\n",
    "    \n",
    "    val_loss, val_acc = validate(model, test_data, criterion, device, class_map)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Training loss: {train_loss}, Training accuracy: {train_acc}\")\n",
    "    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_acc}\")\n",
    "    \n",
    "print(\"Training Done!\")\n",
    "print(\"Best training accuracy: \", max(train_accs))\n",
    "print(\"Best validation accuracy: \", max(val_accs))\n",
    "# plot(train_losses, train_accs, val_losses, val_accs, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b67b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Test Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 15987/36500 [05:53<08:04, 42.36it/s]"
     ]
    }
   ],
   "source": [
    "########################################Train & Validate#####################################################\n",
    "epochs = 100\n",
    "train_loader = Places365(batch_size=32)\n",
    "print(\"Retrieved Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9597bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model setup\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1141 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "print(\"Model setup\")\n",
    "\n",
    "for _ in range(epochs):\n",
    "    print(f\"Epoch {_}\")\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, loss, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    val_loss, val_acc = validate(model, valid_loader, loss, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Training loss: {train_loss}, Training accuracy: {train_acc}\")\n",
    "    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_acc}\")\n",
    "print(\"Training Done!\")\n",
    "print(\"Best training accuracy: \", max(train_accs))\n",
    "print(\"Best validation accuracy: \", max(val_accs))\n",
    "plot(train_losses, train_accs, val_losses, val_accs, model_name)\n",
    "\n",
    "# Save Model\n",
    "pickle.dump(model, open(filename, \"wb\"))\n",
    "print(f\"Model saved on {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597dbc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from focuseddropout import FocusedDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170446eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Type\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, expansion: int = 1, downsample: nn.Module = None, dropout_rate: float = 0.2) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # Multiplicative factor for the subsequent conv2d layer's output channels.\n",
    "        # It is 1 for ResNet18 and ResNet34.\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=3, \n",
    "            stride=stride, \n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.drop = FocusedDropout(par_rate = 0.1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, \n",
    "            out_channels*self.expansion, \n",
    "            kernel_size=3, \n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "        return  out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, img_channels: int, num_layers: int, block: Type[BasicBlock], num_classes: int  = 1000, dropout_rate: float = 0.2) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers == 18:\n",
    "            # The following `layers` list defines the number of `BasicBlock` \n",
    "            # to use to build the network and how many basic blocks to stack\n",
    "            # together.\n",
    "            layers = [2, 2, 2, 2]\n",
    "            self.expansion = 1\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        # All ResNets (18 to 152) contain a Conv2d => BN => ReLU for the first\n",
    "        # three layers. Here, kernel size is 7.\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=7, \n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.drop = FocusedDropout(par_rate = 0.1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512*self.expansion, num_classes)\n",
    "        \n",
    "        \n",
    "    def _make_layer(self, block: Type[BasicBlock], out_channels: int, blocks: int, stride: int = 1) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            \"\"\"\n",
    "            This should pass from `layer2` to `layer4` or \n",
    "            when building ResNets50 and above. Section 3.3 of the paper\n",
    "            Deep Residual Learning for Image Recognition\n",
    "            (https://arxiv.org/pdf/1512.03385v1.pdf).\n",
    "            \"\"\"\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels, \n",
    "                    out_channels*self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False \n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channels, out_channels, stride, self.expansion, downsample\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(\n",
    "                self.in_channels,\n",
    "                out_channels,\n",
    "                expansion=self.expansion\n",
    "            ))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # The spatial dimension of the final layer's feature \n",
    "        # map should be (7, 7) for all ResNets.\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c552b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdata import get_data\n",
    "from train import train, validate\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1e486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = get_data(batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4d04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "lst = []\n",
    "for image, label in valid_loader:\n",
    "    if i < 128:\n",
    "        lst.append((image[0], label.item()))\n",
    "        i+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8ef9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lst, \"test_data.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
